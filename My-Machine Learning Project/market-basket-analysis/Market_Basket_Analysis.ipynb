{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "Pfkzh6bn6eOP",
    "outputId": "63545d5c-1a9c-4389-d133-97d036af9d40"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-52e7838eb421>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#upload kaggle.json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload() #upload kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwxb0z-l6scs"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO8050G_Yj9E"
   },
   "source": [
    "# Spark Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hmW7p4Z4LwtH",
    "outputId": "95525696-7827-4742-f14b-d5943f8d1b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
      "Collecting py4j==0.10.9\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): still running...\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=87156c48bdcc65ca2e4b612bc016e9a8d198e6ac799ec421c68a7e3549310dc7\n",
      "  Stored in directory: c:\\users\\nehad\\appdata\\local\\pip\\cache\\wheels\\df\\88\\9e\\58ef1f74892fef590330ca0830b5b6d995ba29b44f977b3926\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2YuBQv6Y6rh"
   },
   "source": [
    "Initialize a SparContext and a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "88zE3FksMH9a"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import collect_set, col, count\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6vk2I_904ILI"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6dd0dd539d37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'spark.driver.memory'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'45G'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         .set('spark.driver.maxResultSize', '10G'))\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(\"MarketBasket\")\n",
    "conf = (conf.setMaster('local[*]')\n",
    "        .set('spark.executor.memory', '4G')\n",
    "        .set('spark.driver.memory', '45G')\n",
    "        .set('spark.driver.maxResultSize', '10G'))\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ved-46QKP1cd"
   },
   "source": [
    "##Mount Drive and import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vN7y3QXOZJ1p"
   },
   "source": [
    "Install and Download Kaggle API's Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKDj03NiFPc0"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQk3bolQT8lk"
   },
   "outputs": [],
   "source": [
    "try :  \n",
    "    import kaggle  \n",
    "      \n",
    "except OSError as error :  \n",
    "    print(error)\n",
    "    ! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaBigPiMZVmD"
   },
   "source": [
    "Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vni269x2GCis",
    "outputId": "01e96b19-5f87-4601-8eb1-495efa96ec9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading imdb-dataset.zip to /content\n",
      "100% 1.44G/1.44G [00:17<00:00, 40.9MB/s]\n",
      "100% 1.44G/1.44G [00:17<00:00, 86.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d ashirwadsangwan/imdb-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCtpwGKJZdOc"
   },
   "source": [
    "Import the Dataset in the COLAB work environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3chTD4bsIZ70",
    "outputId": "fcbd195c-a51b-4c31-b3e4-96ee903aea11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = \"imdb-dataset.zip\"\n",
    "\n",
    "with ZipFile(file_name, \"r\") as zip:\n",
    "  zip.extractall()\n",
    "  print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb5rnO2eQBG-"
   },
   "source": [
    "##Filter actor and movies by using sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhcYhnGu0Aw0"
   },
   "source": [
    "From title principals table, filter just actor and actress, that will be the items of the analysis.\n",
    "Then select just the columns of interest: tconst (the movies' code) and nconst (the actor's code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilTBhDpPNdV4",
    "outputId": "79255729-6378-4e0c-c35c-bd73be20b023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+---------------+--------------------+-----------+\n",
      "|   tconst|ordering|   nconst|       category|                 job| characters|\n",
      "+---------+--------+---------+---------------+--------------------+-----------+\n",
      "|tt0000001|       1|nm1588970|           self|                  \\N|[\"Herself\"]|\n",
      "|tt0000001|       2|nm0005690|       director|                  \\N|         \\N|\n",
      "|tt0000001|       3|nm0374658|cinematographer|director of photo...|         \\N|\n",
      "|tt0000002|       1|nm0721526|       director|                  \\N|         \\N|\n",
      "|tt0000002|       2|nm1335271|       composer|                  \\N|         \\N|\n",
      "+---------+--------+---------+---------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "title_principals = 'title.principals.tsv.gz'\n",
    "title_principals = sqlContext.read.csv(title_principals, header=True, sep = '\\t')\n",
    "\n",
    "title_principals.show(5)\n",
    "\n",
    "title_principals = title_principals.filter((title_principals.category == \"actor\") | (title_principals.category == \"actress\"))\n",
    "title_principals = title_principals.select(col(\"tconst\"),col(\"nconst\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHrYI19t0fVO"
   },
   "source": [
    "From title basics table filter just the movies, that will be the baskets of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdN7an5jxlxo",
    "outputId": "8a87a5b0-9898-4615-ab43-5e6e21766cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "|   tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|              genres|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "|tt0000001|    short|          Carmencita|          Carmencita|      0|     1894|     \\N|             1|   Documentary,Short|\n",
      "|tt0000002|    short|Le clown et ses c...|Le clown et ses c...|      0|     1892|     \\N|             5|     Animation,Short|\n",
      "|tt0000003|    short|      Pauvre Pierrot|      Pauvre Pierrot|      0|     1892|     \\N|             4|Animation,Comedy,...|\n",
      "|tt0000004|    short|         Un bon bock|         Un bon bock|      0|     1892|     \\N|            \\N|     Animation,Short|\n",
      "|tt0000005|    short|    Blacksmith Scene|    Blacksmith Scene|      0|     1893|     \\N|             1|        Comedy,Short|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_basics = 'title.basics.tsv.gz'\n",
    "title_basics = sqlContext.read.csv(title_basics, header=True, sep = '\\t')\n",
    "\n",
    "title_basics.show(5) # print example\n",
    "\n",
    "#Filter by movies\n",
    "title_basics = title_basics.filter((title_basics.titleType == \"movie\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k7NhIBK0tp2"
   },
   "source": [
    "With a left join operation, combine title principle and title basic table in order to obtain just the actors appearing in movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I51143D9zE_l",
    "outputId": "6b5ce34d-fd21-4f00-d6a9-745032367556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|   tconst|   nconst|\n",
      "+---------+---------+\n",
      "|tt0002591|nm0029806|\n",
      "|tt0002591|nm0509573|\n",
      "|tt0003689|nm0694718|\n",
      "|tt0003689|nm0101071|\n",
      "|tt0003689|nm0910564|\n",
      "+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_principals = title_principals.join(title_basics, [\"tconst\"], 'leftsemi')\n",
    "title_principals.show(5) # print example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8YdcFYQbFKQ",
    "outputId": "3bc8728a-e654-4b91-cdb3-e3d372675bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "|   nconst|    primaryName|birthYear|deathYear|   primaryProfession|      knownForTitles|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "|nm0000001|   Fred Astaire|     1899|     1987|soundtrack,actor,...|tt0050419,tt00531...|\n",
      "|nm0000002|  Lauren Bacall|     1924|     2014|  actress,soundtrack|tt0117057,tt00373...|\n",
      "|nm0000003|Brigitte Bardot|     1934|       \\N|actress,soundtrac...|tt0049189,tt00599...|\n",
      "|nm0000004|   John Belushi|     1949|     1982|actor,writer,soun...|tt0078723,tt00804...|\n",
      "|nm0000005| Ingmar Bergman|     1918|     2007|writer,director,a...|tt0050986,tt00839...|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import name_basics table\n",
    "name_basics_path = 'name.basics.tsv.gz'\n",
    "name_basics = sqlContext.read.csv(name_basics_path, header = True, sep = '\\t')\n",
    "name_basics.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kSpcgOUQ17T"
   },
   "source": [
    "#Implementation of a-priori and SON algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6jnu3OZ7fBO"
   },
   "outputs": [],
   "source": [
    "#DEFINITION OF FUNCTIONS:\n",
    "\n",
    "#Definition of sum function\n",
    "def sum_actors(x,y):\n",
    "    return x+y\n",
    "\n",
    "#Definition of filtering functions: it checks if a set of item is a subset of a basket.\n",
    "def filtering(rddlist, filt):\n",
    "  for item in filt:\n",
    "    if set(list(item)).issubset(set(rddlist)):\n",
    "      return ((item, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzJCO90DwvE5"
   },
   "source": [
    "#A-Priori algorithm: \n",
    "\n",
    "Implementation of A-Priori algorithm to retrieve the frequent pairs of actors.\n",
    "The function takes in input an RDD and a threshold.\n",
    "The function is composed by the combination of the main Spark's functions: map, reduce and filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozPssDPCRO6s"
   },
   "outputs": [],
   "source": [
    "def apriori(rdd, threshold):\n",
    "  \n",
    "  flat_list  = rdd.flatMap(list) \n",
    "\n",
    "  singleton = flat_list.map(lambda item: (item , 1)) #add one for each actor appearence\n",
    "  singleton_summed = singleton.reduceByKey(sum_actors) #sum of values by actor as key\n",
    "  singleton_filtered = singleton_summed.filter(lambda item: item[1] >= threshold ) #consider items that appear singularly a number of time larger than the threshold in the baskets.\n",
    "\n",
    "  #obtain a list of the codes of the items\n",
    "  frequent_actors = singleton_filtered.map(lambda item: (item[0]))\n",
    "\n",
    "  #Obtain all the pairs of frequent items:\n",
    "  pairs_list = list(itertools.combinations(frequent_actors.toLocalIterator(),2))\n",
    "\n",
    "  #Create the support table for the pairs of items by applying the filtering function previously created.\n",
    "  support_table_pairs = rdd.map(lambda x : filtering(x, pairs_list)).filter(lambda x: x is not None).cache() #Apply filtering function to check if a pairs appear in the movies\n",
    "  support_table_pairs_summed = support_table_pairs.reduceByKey(sum_actors) # sum of values by actor as key\n",
    "  support_table_pairs_filtered = support_table_pairs_summed.filter(lambda item: item[1] >= threshold) #consider just the actor that performed in more than support value\n",
    "\n",
    "  return (support_table_pairs_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWXz--fMTLcF"
   },
   "source": [
    "#SON algorithm:\n",
    "\n",
    "It is an exact algorithm that fit well in a context in which data are split in chunks (in our case RDD). \n",
    "It consists in applying A-Priori algorithm in each chunks by considering an adjusted threshold, merge the results and then perform a scan on the baskets to identify possible *false positive.*\n",
    "\n",
    "In our case we are interested in identify the pairs of actors that appear together more than 140 times (minimum threshold = 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6wSPGCprn_D",
    "outputId": "7bde02a9-e8a3-4468-f515-a10ad9c19b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nm0029806', 'nm0509573'], ['nm0910564', 'nm0527801', 'nm0399988', 'nm0101071', 'nm0694718', 'nm0728289', 'nm0585503']]\n"
     ]
    }
   ],
   "source": [
    "#create a list containing baskets: each basket is a movie and it is a list containing the actors that performed in that film\n",
    "baskets = title_principals.groupBy(\"tconst\").agg(collect_set(\"nconst\").alias(\"actors\"))\n",
    "\n",
    "#list of baskets containing actors divided by movies\n",
    "basket_list = baskets.select('actors').rdd.flatMap(list)\n",
    "\n",
    "#Parallelize the list in RDD\n",
    "basket_list = sc.parallelize(basket_list.collect(), 5)\n",
    "\n",
    "print(basket_list.collect()[:2]) #print example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylzE6O47GaFE",
    "outputId": "18799f2b-85e5-4dbc-fc05-5e4d3c60bc75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket_list.getNumPartitions() #check number of partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfx4JT2tzDPt"
   },
   "source": [
    "Setting the support and adjust it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IQoeLQfOR9M",
    "outputId": "820c5f44-656d-4020-8fdc-b7ee4d94b452"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minSupport = 140\n",
    "numPartitions = basket_list.getNumPartitions()\n",
    "adjSupport = minSupport/numPartitions\n",
    "adjSupport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwEEEhP_zHSs"
   },
   "source": [
    "Implementation of the SON algorithm procedure by including a-priori algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfHId8s5ThX0"
   },
   "outputs": [],
   "source": [
    "candidates = sc.parallelize([]) #create a RDD to merge the result of apriori applied on each chunk.\n",
    "\n",
    "for i in range(0, numPartitions-1):\n",
    "  \n",
    "  partition = sc.parallelize(basket_list.glom().collect()[i]) #collect each partition\n",
    "  support_table_pairs_filtered = apriori(partition, adjSupport)\n",
    "  candidate_chunk = support_table_pairs_filtered.map(lambda item: (item[0],1))\n",
    "  candidates = candidates.union(candidate_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2eP0mc7Ulu2",
    "outputId": "beda249e-7d63-4dc6-e407-84c8c70d29ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('nm0623427', 'nm0006982'), 1), (('nm2082516', 'nm0648803'), 1)]\n"
     ]
    }
   ],
   "source": [
    "print(candidates.collect()[:5]) #print example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJN8W7gZtJ6Z",
    "outputId": "31199434-5eb3-46a3-fbcd-b68b1a2f2c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------+\n",
      "|actor_pair            |movies|\n",
      "+----------------------+------+\n",
      "|{nm0623427, nm0006982}|1     |\n",
      "|{nm2082516, nm0648803}|1     |\n",
      "+----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert the RDD to dataframe\n",
    "deptColumns = [\"actor_pair\",\"movies\"]\n",
    "candidates_set = candidates.toDF(deptColumns)\n",
    "candidates_set.createOrReplaceTempView(\"candidates_set\")\n",
    "sqlContext.sql(\"SELECT * FROM candidates_set ORDER BY movies DESC\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEGQQwJVzfvp"
   },
   "source": [
    "Obtain the codes of the candidate actors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZ7ySW3LEKzQ"
   },
   "outputs": [],
   "source": [
    "candidates_actors = candidates.map(lambda item : item[0])\n",
    "candidates_list = candidates_actors.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l79VNNL1zbVF"
   },
   "source": [
    "Check for possible false positive by scanning the baskets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fxzu_QzuOSPY",
    "outputId": "71f2e9e6-06f1-44fa-ea77-60c89495ad46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('nm2082516', 'nm0648803'), 147), (('nm0623427', 'nm0006982'), 236)]\n"
     ]
    }
   ],
   "source": [
    "candidates_check = basket_list.map(lambda x : filtering(x, candidates_list)).filter(lambda x: x is not None).cache()\n",
    "candidates_summed = candidates_check.reduceByKey(sum_actors)\n",
    "candidates_filtered = candidates_summed.filter(lambda item: item[1] >= minSupport)\n",
    "\n",
    "print(candidates_filtered.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GljIWDtxzozT"
   },
   "source": [
    "Print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPHWItSosc6s",
    "outputId": "b223cc7f-6bf2-411e-84f7-5ca699ec5b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------+\n",
      "|actor_pair            |movies|\n",
      "+----------------------+------+\n",
      "|{nm0623427, nm0006982}|236   |\n",
      "|{nm2082516, nm0648803}|147   |\n",
      "+----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#convert the  RDD to dataframe\n",
    "deptColumns = [\"actor_pair\",\"movies\"]\n",
    "results = candidates_filtered.toDF(deptColumns)\n",
    "results.createOrReplaceTempView(\"results\")\n",
    "sqlContext.sql(\"SELECT * FROM results ORDER BY movies DESC\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4hOiHXbNb_3"
   },
   "source": [
    "#Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHb6sKGaOIXO"
   },
   "source": [
    "To calculate the confidence we need to obtain the number of movies each of these actors performed singularly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-y3zA8RfOjJm",
    "outputId": "13df087f-4940-4473-d05b-0dc504c7b1e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|actors   |movies|\n",
      "+---------+------+\n",
      "|nm0103977|797   |\n",
      "|nm0006982|585   |\n",
      "|nm0648803|565   |\n",
      "|nm0305182|506   |\n",
      "|nm0623427|436   |\n",
      "+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#list of all actors    \n",
    "flat_list  = basket_list.flatMap(list)\n",
    "\n",
    "#obtain the actors that performed in a number of movies larger than the threshold:\n",
    "singleton = flat_list.map(lambda item: (item , 1)) #add one for each actor appearence\n",
    "singleton_summed = singleton.reduceByKey(sum_actors) #sum of values by actor as key\n",
    "singleton_filtered = singleton_summed.filter(lambda item: item[1] >= minSupport ) #consider just the actor that performed in more than support value\n",
    "\n",
    "#convert the first support RDD to dataframe\n",
    "deptColumns = [\"actors\", \"movies\"]\n",
    "first_df = singleton_filtered.toDF(deptColumns)\n",
    "first_df.createOrReplaceTempView(\"first_df\")\n",
    "sqlContext.sql(\"SELECT * FROM first_df ORDER BY movies DESC\").show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQni1yJiPNgY"
   },
   "source": [
    "We combine this information with the name_basics table to obtain the name of the actors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RjUhWnAZPOGF",
    "outputId": "4b0f8d30-b848-4285-ad72-66a56494b7aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+------+\n",
      "|primaryName |actors   |movies|\n",
      "+------------+---------+------+\n",
      "|Kijaku Ôtani|nm2082516|161   |\n",
      "+------------+---------+------+\n",
      "\n",
      "+----------------+---------+------+\n",
      "|primaryName     |actors   |movies|\n",
      "+----------------+---------+------+\n",
      "|Matsunosuke Onoe|nm0648803|565   |\n",
      "+----------------+---------+------+\n",
      "\n",
      "+-----------+---------+------+\n",
      "|primaryName|actors   |movies|\n",
      "+-----------+---------+------+\n",
      "|Prem Nazir |nm0623427|436   |\n",
      "+-----------+---------+------+\n",
      "\n",
      "+-----------+---------+------+\n",
      "|primaryName|actors   |movies|\n",
      "+-----------+---------+------+\n",
      "|Adoor Bhasi|nm0006982|585   |\n",
      "+-----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_basics.createOrReplaceTempView(\"name_basics\")\n",
    "\n",
    "#retrieve the name of the most frequent actors from the name_basics table\n",
    "sqlContext.sql(\"SELECT primaryName, actors, movies  FROM (first_df INNER JOIN name_basics ON actors = nconst) WHERE actors = 'nm2082516'\").show(truncate = False)\n",
    "sqlContext.sql(\"SELECT primaryName, actors, movies  FROM (first_df INNER JOIN name_basics ON actors = nconst) WHERE actors = 'nm0648803'\").show(truncate = False)\n",
    "\n",
    "sqlContext.sql(\"SELECT primaryName, actors, movies  FROM (first_df INNER JOIN name_basics ON actors = nconst) WHERE actors = 'nm0623427'\").show(truncate = False)\n",
    "sqlContext.sql(\"SELECT primaryName, actors, movies  FROM (first_df INNER JOIN name_basics ON actors = nconst) WHERE actors = 'nm0006982'\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42VyN5tOsJe8"
   },
   "source": [
    "It is possible to calculate the confidence that says how likely actor Y appears when actor X also appears: Confidence{X -> Y}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ajx34Tkos4nz",
    "outputId": "511ad73d-d125-4d6c-99cc-ee40f8696761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probabilty that Onoe appears in a movie given the presence of Otani is 0.91.\n",
      "The probability that Otani appears in a movie given the presence of Onoe is 0.26\n",
      "The probabilty that Nazir appears in a movie given the presence of Bhasi is 0.4.\n",
      "The probability that Bhasi appears in a movie given the presence of Nazir is 0.54\n"
     ]
    }
   ],
   "source": [
    "#Confidence computation:\n",
    "#Confidence that given Otani there is also Onoe = Confidence{Otani -> Onoe} and viceversa\n",
    "confidence_OT_ON = round(147/161, 2)\n",
    "confidence_ON_OT = round(147/565, 2)\n",
    "\n",
    "#Confidence that given Bhasi there is also Nazir and viceversa\n",
    "confidence_BH_NA = round(236/585, 2)\n",
    "confidence_NA_BH = round(236/436, 2)\n",
    "\n",
    "print(\"The probabilty that Onoe appears in a movie given the presence of Otani is {}.\\nThe probability that Otani appears in a movie given the presence of Onoe is {}\".format(confidence_OT_ON, confidence_ON_OT))\n",
    "print(\"The probabilty that Nazir appears in a movie given the presence of Bhasi is {}.\\nThe probability that Bhasi appears in a movie given the presence of Nazir is {}\".format(confidence_BH_NA, confidence_NA_BH))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPtGU/MDopH1RBuEXbiweWM",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Market-Basket Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
